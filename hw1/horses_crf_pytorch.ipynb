{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lCWOiVlevMg1"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QgPkJt9Bux-J"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_horses_orig(path, image_size):\n",
        "    mask_path = path + 'masks/'\n",
        "    image_path = path + 'images/'\n",
        "    images = []\n",
        "    masks = []\n",
        "    test_images= []\n",
        "    test_masks =[]\n",
        "    for i in range(328):\n",
        "        orig_im = cv2.imread(image_path + 'image-{}.png'.format(i))\n",
        "        orig_im= cv2.cvtColor(orig_im, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        low_im = cv2.resize(orig_im, dsize=(image_size, image_size))\n",
        "\n",
        "        orig_mask = cv2.imread(mask_path + 'mask-{}.png'.format(i))\n",
        "        low_mask = cv2.resize(orig_mask, dsize=(image_size, image_size))\n",
        "        low_mask = cv2.cvtColor(low_mask, cv2.COLOR_RGB2GRAY)\n",
        "        bin_mask = (low_mask > 0) + 0\n",
        "\n",
        "\n",
        "        images.append(low_im)\n",
        "        masks.append(bin_mask)\n",
        "\n",
        "\n",
        "    xtest = np.reshape(np.array(images[250:]), (-1,image_size*image_size*3))\n",
        "    ytest = np.reshape(np.array(masks[250:]), (-1, image_size * image_size))\n",
        "    xdata = np.reshape(np.array(images[:200]), (-1,image_size*image_size*3))\n",
        "    ydata = np.reshape(np.array(masks[:200]), (-1, image_size * image_size))\n",
        "    yval =  np.reshape(np.array(masks[200:250]), (-1, image_size * image_size))\n",
        "    xval = np.reshape(np.array(images[200:250]), (-1,image_size*image_size*3))\n",
        "\n",
        "\n",
        "    return xdata, xval, xtest, ydata, yval, ytest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ziLhzr0SvHS2"
      },
      "outputs": [],
      "source": [
        "#change the path address\n",
        "path = 'horses/horses/'\n",
        "image_size = 32;\n",
        "xdata, xval, xtest, ydata, yval, ytest = load_horses_orig(path, image_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sYxdYG-vrxgK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 99,  78,  50, ..., 111, 105,  81],\n",
              "       [241, 241, 241, ..., 209, 209, 209],\n",
              "       [122, 148, 113, ..., 179, 188, 110],\n",
              "       ...,\n",
              "       [167, 157, 117, ..., 169, 148, 108],\n",
              "       [223, 223, 223, ..., 163, 112,  68],\n",
              "       [236, 157,  34, ..., 126,  93,  63]], dtype=uint8)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1fMebn_tRrw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fYU3V-_O7TZV"
      },
      "outputs": [],
      "source": [
        "def draw(image, mask):\n",
        "  fig, (ax1,ax2) = plt.subplots(1,2)\n",
        "  ax1.axis('off')\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(np.reshape(image, (image_size,image_size,3)))\n",
        "  ax2.imshow(np.reshape(mask, (image_size,image_size)), cmap=plt.cm.gray)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lzdIqN66Xt7s"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAD1CAYAAADNj/Z6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAY3UlEQVR4nO3deZCkd13H8e/T9zHdc/XM7Ozu7JHZK1nikgNCCGFJghhjIJYSIoUVtETWogiWRakQoETUAAX6D0oBFmWhmCJaiIhGDEeE3VzkZpPsvbPH7M493TPT3dN3+4d/WeXnt12TzGY2v/fr3w9PH8/zDPnWU/vpb9But9sGAAC8FXq1PwAAAHh1MQwAAOA5hgEAADzHMAAAgOcYBgAA8BzDAAAAnmMYAADAcwwDAAB4jmEAAADPRTr9H37gjmtkljP9I4anJudl1tOXldmbrtols/9+6ojM1m+4TGeDGZnt2jkqMzOzL379fpndsfeNMrvxxmtlVsjXZTY1MS2zA8+/KLMtsYrMNu/U53Rq/LjMlkoyskdeOKRfc74hs+2b+mW2UC7KLBbV82sQisvMzOylUxMyy0T1n8JcRV+nxZI+3+2Q/qwfv0vfM7l1vTJ73ye/I7O1KgiCV/sjAN670I8N82QAAADPMQwAAOA5hgEAADzHMAAAgOcYBgAA8FzHbYLLhjbI7Mvf/S+Z3fGW18nsnW+9Tma1Rkpmd75nk8zmJ+ZkFooOyCyVcv9L9L6emMz2739aZrv3XCGzQ888K7Nj56dklojrz3KmWJXZ4qETMvubf9kvs0xKz4xl/Y/pLRrR/4r86JS+TlHHvz5fDnRDIWi4/7VsIpaW2Ttu3CizXE7fN/PVmsxSYf09Mr19MmvUWzIDgNXAkwEAADzHMAAAgOcYBgAA8BzDAAAAnmMYAADAcwwDAAB4ruNq4eRsXmafff9tMktn9XKgrZfpuqKVl2T0/Uefkdlwv37NVDYqs3hW1/XMzNY7lsc8e/akzPLHdJ1vvqIrZOfm9HagJ555TmabN3bLrFZaltnWDXpp1O71+rtvWqffL1/SNcBKS1+LVlLXPEsLupK49/rXy8zMLD+tlz/t2jQosxOTszLbM6AXY2UDXfPsGtCLmpYL+m8NAFYDTwYAAPAcwwAAAJ5jGAAAwHMMAwAAeI5hAAAAzzEMAADguY6rham0rsEN9Outbi3T9bKpUxMyS8Qdc0qgP3YorDfX5TYMyywV1zUwM7MTY7rSlnBU4X7n89+S2dCg3qK33VHnu+laXWcbny3K7O237JbZ6Mg6mY0dPyazt918g8yOHdG1ysGNm2U27aixbhnR7zc/cVZmZmZX3/YrMtt65S6ZZX/6qMwiTV0BbSzpemyrVpdZpsu9fREAXmk8GQAAwHMMAwAAeI5hAAAAzzEMAADgOYYBAAA8xzAAAIDnOq4WhnVD0M5MzMisK6G3003N6brewSNnZLZnu67WPfDgIzJL//SgzJ46el5mZmYTc7ru9vt3vkVm112xSWaXj+qq4wbHNsCHHjuiX3Ojrgheee3rZNazbr3MYq2mzA6fOKePS6dkNj45LrPr3narzBKBrrgmU2GZmZnVivo+rS7pa5FI6j+T2rK+vzdt1q+Z27NHZi/88HsyA4DVwJMBAAA8xzAAAIDnGAYAAPAcwwAAAJ5jGAAAwHMMAwAAeK7jauHUzLzMTp4vyOzxn4/J7DfeMiqzdJfe2vfUIb1Fb7akq2e7Xqfrc2cmdNXNzOzqndtldsvrN8jsB0/q718plvXnmdabELsTCZmlU/q4dl5v0csO6VthJhrIrFGtySy0XJHZjXtvkln3YJfMnjvwuMystKAzMyuU9abAoSF9b4xs1dnYc4dkFuvpk1nNce2TGb0FFABWA08GAADwHMMAAACeYxgAAMBzDAMAAHiOYQAAAM8xDAAA4LmOq4WxZFJm5+Z17fD1jlrW1dscW/tGcjKbXh6RWfjFSZlt36g/y/1zVZmZmfX16/xRx3smo7rqNzDYI7Ou/iGZLS/oCl0skpZZtaKrhUeOHJdZtltvUFw6r7cWbl+vNyjOjZ+WWaixKLNNG/R9cfaQu1o43K/rqqcPPy+zWFJXBIc26ns4EtVVxsKs3qC4sKSvEwCsBp4MAADgOYYBAAA8xzAAAIDnGAYAAPAcwwAAAJ5jGAAAwHMdVwsPn5mQ2V98+Fdl9q3vPSmz5ZCuwW27crPMnvjPkzLryqRkVm6GZZbtysjMzGz/83qr4d23vEFmy62GzEZ3bJPZoSN62+HgsK6zBTU939XauupWquhaXiSuK3l9PbquGU7oOmq9qbdLlhr6tlyanZVZI6y3K5qZLRULMsv2D8osGovKLJV2nG9HQ/DM80/LbGxqTmZv0y+JV0m73V7xsUHgvmeBi4UnAwAAeI5hAAAAzzEMAADgOYYBAAA8xzAAAIDnGAYAAPBcx9XC+VJTZkFSV68uH9UVweGBhMwmj+kqY7lak1l/XNcHc0P6s4zqFpyZmc029dz0mb//kczeuFvXB7duv0Jmuf5NMuvt19/x2EvTMmundUWwdFZvEZxfPCuzSkPfF4vFssyGcrrK1wjrmmN+RlcLz+f1tkMzs96EroAVCkWZ7dqqq5ynntbnO9yl7+9CW99PjRAzui9WWkukkohXGv+vAwCA5xgGAADwHMMAAACeYxgAAMBzDAMAAHiOYQAAAM8xDAAA4LmOf2fg0/tuk9l0sSSzwlJFZoPb+2VWLun9r1fs2CizQ4f17xOM7tTrdh8fL8jMzKzZ1KuI83P6+3/tQb3C+Wv/8YTM7v/078nsqaO6h5+O6kvaXNLntGm675xf0L8XMDGle/9BrSqzytZl/ZqT+ncr8vmCzBIJ9+3cm9C9/3QmLrPMsL5vciH9nvn5Kf1ZBvTK7FBIr3fGq+PlrCleDa7Pw28QYCV4MgAAgOcYBgAA8BzDAAAAnmMYAADAcwwDAAB4jmEAAADPdVwtHEzqVbVHJ/X618KyrhY+clCvxt02pKteW0Z1tfDo0TMy+9a998lsMKrXApuZHS/XZdYf1qcxFNbrlttt/Z73fPbrMvvUh+6Q2Znzuuq3blDX2Symz3cikZJZzdGC27xuSL9mJCazVFeXftGKXlO8UNHXyMys0t4gs+t375RZ2lEDjMT196iHdf3rhf26VhpO6dcELoTaIVaCJwMAAHiOYQAAAM8xDAAA4DmGAQAAPMcwAACA5xgGAADwXMfVwmOn8zJLpHUVKojoWtpyTW/DS+W2yWzmrK4kPvzkQZnN5vUWvZm6u5bWdmzE647omSod0uem1NS1y3xLv+b4VEFmu7dv0a85p7fonZ3QrxlP6y2CuR5du6vXda0yqOmK01IlLbOBrVtkdu99D8jMzKxW2y+zD926W2Yf2XenzCp1Xbl9/NFnZRaK6g2KrWV93rB61tpmQlw8q3XtL6UqJ08GAADwHMMAAACeYxgAAMBzDAMAAHiOYQAAAM8xDAAA4Lmg3WGn4qt/oDfl5QtzMiu2e2SWcmz0682tk1k23JDZwy/qrYXNZLfMWssFmZmZzcyUZFafmpbZyYLe6DjSm5XZgXF9TgPTqwIf+Py9Mvvug9+V2XJNVytv+IXNMhs7PSmziCVl9sL4eZlds0Nvpfz8934ms5Bu+f2vQN83LdN/BjsHe2V2/VV62+GTL5zSx12pv+O7bnqDzG778JdktlZdSvUqZbU2Aa6lOuNauk4rPS+u77CWzrXZ6nzWl/OaPBkAAMBzDAMAAHiOYQAAAM8xDAAA4DmGAQAAPMcwAACA5zquFn7sN2+W2XCfruw16/rliy3dBatH4jJrlfX2wUpLV+SGcnqDYtuxXdDM7PhRvSlx8chJmW3I6PrgVF1X3f75qK7shUL6uF/britrozl9nY5Oz8rs2KyuR17RqzcMji3orZS5bn0tnp0pyGyi7OgPNnTl0swscHQPIxHHAk/Hn0g40PN0NKRrPp9671tlttjS2yz/5CsPy2ytWkuVtbVmrdXdcGmjWggAAFaMYQAAAM8xDAAA4DmGAQAAPMcwAACA5xgGAADwnKNP9X8FoajMjhV0pauvS88bPRGdlWMJmS009XE7u/RxiyF93E3X6O1zZmYvvnhKZleM6A2LzflF/aIJXWfsSuiKyD27N8lsR1+PzAa79DWsL+hbYcpxnX5xs64WfuFpXUksTOtsYzojs0hC32tT8wWZmZltGR6SWTqpv/+RszMyyzk+6+6NOZkttPU5nV3U9VgAflutqi5PBgAA8BzDAAAAnmMYAADAcwwDAAB4jmEAAADPMQwAAOC5jquFhbqudGUctaxwU2+KK0f1caPremX2zJFxmZ0u6I1+S9UlmY1NDcvMzGz7Zr3x78iY3vj39n69nc8SejPjPSm9ffDmzboiFw50XTGd1LPfSF9BZj85uyCzR07r7Je3DcrssdNzMutJ6++Qd2zBXD/svoYbh3TtdMjxniM5XR8cTutrGA6FZXb3vrtl9uef+ZzM8NrycrbM4ZXDZk2eDAAA4D2GAQAAPMcwAACA5xgGAADwHMMAAACeYxgAAMBzHVcLm3Vd2Yt21WQ256iCRSr6uNjZSZlVHZ+lFZRkFiqXZfaNf/uRzMzMso6xKT9XlVmzX5/inx7WFclrBnQl8fJuXYM7WdYb72pNXXV7aUqft1gmKbPJqv7u3U2dZWL6sxyfK+jPktWV020jfTIzM9ue0+dtOq9rpxsS+rNOLOjzdt1Vu2U2d1pf+z+85/0yA4DVwJMBAAA8xzAAAIDnGAYAAPAcwwAAAJ5jGAAAwHMMAwAAeK7jamG+qut8kaKuV60b0FWwkUG9fW+5oDcB1s/rTXnRqIxsqay/w9x8RR9oZkFSb7ybXlyW2UJ3Wma3bOmX2Zde0tWzfbfvkVnSUVcsJrtk9tC5GZkt1PTM+IUbNsusVNPn++SCrnlWF/Smy4/+9p0yWzegK5BmZo26rl22Ar2VMxnXlcRsl76+1YquVp4+q893Vy4rs8tlAgArx5MBAAA8xzAAAIDnGAYAAPAcwwAAAJ5jGAAAwHMMAwAAeK7jauHubetk1m4FMqs1dJ1rKq8rgnMLupY1vHm9zCIhXWcbDo/I7IYbdQXSzGwhr6uOA/16W17w44dk9tC4rtfNLOuNjpUlfW4mF4oy+9EZvZlv3rHRsB7Smyc/fOCEzN46rM9Ls61fs9nS2fz0nMx6Uu6thZPnde2yd1jf37WyPm/1pq4klkr6+paXdZX19NyUzG6VCQCsHE8GAADwHMMAAACeYxgAAMBzDAMAAHiOYQAAAM8xDAAA4LmOq4XJuN54t7CQl1nQ0lW/sdOTMusb6JZZu6632rVjer6JxeMyO3P2rMzMzMK6eWejCb0t76Wa3nb4YkHX5KYdSxTveOA5maWS+vs/P6/rijddf6XMfsmRPXbwpMz+/fuPyex3b7lKZkcP/Fxm45O6dtfb77hIZpYayMls0VEf7HJc36WiPq5Y0tss42G9XjPXOyAz4FISBLp23nbUi3Hx8WQAAADPMQwAAOA5hgEAADzHMAAAgOcYBgAA8BzDAAAAnuu8WpjUtbxjx3S18LItwzI7clLXxHbu3CizWlVX5HoyugZWbznqXIODMjNzV2T+6eEnZPbwQV1Z/ON77pLZJ/7yH2S2+01Xy2zX5fp8v0MvkLQg0DWfRlt/9zdfdZnM7qpMyOzr+ZLMvnrXtfo1v/mwzD62470yMzMLl/XmSVfLKeOoqy4WdXU26qpVRfW9WKsU9IfBa8pK63WrUdlzveZqoHa4tvBkAAAAzzEMAADgOYYBAAA8xzAAAIDnGAYAAPAcwwAAAJ7ruFo4Oz8vs56+jMzagZ43rtmzQ2bNmq6dNNt6O91soSyzUkV366Ihd5Wl5Vhb+OOnj8rs3e/cK7PCvK5k3rZ3j8x+8MP9Mhvov0lmrv5c3LHR8dxiQWZ92V6ZTWR0Nn1Ybzv8weiQzCpNvbHy/m9/X2ZmZnff/maZpVL6Hl6qVGWWTKZl1mjq40oVvZYyiFzcihfWpotd9VtLVlo7XOlxF6oy+nAteDIAAIDnGAYAAPAcwwAAAJ5jGAAAwHMMAwAAeI5hAAAAz3VcLWw7Kl2ubLGkK1Ttln6/ZrMoM9cE09ujq159fbrqVlvWlUQzs6Vlnd2+900yy2T1FsVqS2+827lts8zKZ/U2wN5eXcuLRHU9MuRozqS7+2QWNn3tLZuV0QsPPiuz923TmxD/9IM5mX3yy9/Rn8XMpvMLMosUdQ1wuqAroMN9PTLr69Z1xXhMVzmXq44/DLymrEZljW2A/z/OixtPBgAA8BzDAAAAnmMYAADAcwwDAAB4jmEAAADPMQwAAOC5jquF8ZiuyGWyukIVDkVlVq6UZBZL6PcLmnqGSSb1cctVXXNMpnUNzsysHdfVk0y2S2aOBpkFbUctz3QN5sB5fd5Gxk7IrFrX79ftqGSWlvT7rcvpumYk3i2z3/r1W2R2bmJSZkVHVTUc0VVNM7Oo42JUK7o7mojqezgS1a85s6Drqumkrg+en5yTGS49K92y5zPO2cXHkwEAADzHMAAAgOcYBgAA8BzDAAAAnmMYAADAcwwDAAB4Lmh3uK7p3e+4Wma5fr3VbmS93qKXSOkaYLmsa1mLi4syizpqYKmUrgCWi3pLopnZ+/Z9VGZ/++UvyqzV0FW4iqMJt3FIn9NqKCGztGMzYeDYkhiP6LkwEnFUeQJdkXvvvo/I7L57/0hmy/WazJIRfX23btkuMzOz6akzMqs29bmpNeoySyf0PRUJ9DkdO3dOZrt26e/xifv+UWZrle9VsEulJreWPufF/iwX+s/gWrpOK3Wh78iTAQAAPMcwAACA5xgGAADwHMMAAACeYxgAAMBzDAMAAHiOYQAAAM91vMJ4dGRAZqF4TGaFkv5NgJzj3ZtN3e2OxXTX3NUHDYV0z7LqWG9sZrZlVP9eQrO4JLNYSq8GLtf1cYXCrMyScf2a33joZzL74Htullmlptcb10p6ve+t77pdZl/54p/JLNOl+/k9jkpvxHHtpybG9IFmtu/j+rcN/vUbfyezal3/lkK9rj/PYz8/JLPx83mZPX7wgMw+cZ+MgEtKhz9xc1Fc6HcE1tJvMKwWngwAAOA5hgEAADzHMAAAgOcYBgAA8BzDAAAAnmMYAADAcx1XC8fnSjLLxHUN0MK6dhF2NEsWivr9GlVdg4vG9PvVqlV9XNQ9F/34rz8ts76hbpk12/rzxJO9MgtMVx3PTc7I7OYbr5TZ9KJjTXNFn+9iW68Uvmw4I7NIOK4z3Y60SFjX9Y6MnZLZ8RNT+kXN7P0zOv/md34is3PTugbYbulabaup79PePr2Gev36dTIDVstaqsitpc/iC54MAADgOYYBAAA8xzAAAIDnGAYAAPAcwwAAAJ5jGAAAwHNBu8PVUR94z16ZReO6odh0tBczjuPM9Ka4tmOGaTi2HUYi+rhIRNfgzMyGs3rL3mFH1S8cCsss1NLfMZtNymy5oY9zLGa04qKuK4Zi+sB4QtfnRntTMnv+9JzMMhldSQy3dQV0sao3KGZj7msYhPX1ry8WZFY0XXU8N6mP6+3OyizXp++nVLfOPvdX35bZWkVN7NK3Glv7XiubAC+V73Gh/9TzZAAAAM8xDAAA4DmGAQAAPMcwAACA5xgGAADwHMMAAACe63hrYc/QoONFdGUhHNJvUa3r45YW52WWTvfIzNUua9YdmxDrjs2LZnauUJBZd1LXAJeWlmRWd5z+pYqu18VCuq6y6Nj22N2ja4DxhF4jGHe0Y5ZaOty6oU9mQaArl5Wqvi8yGX2uw2H9mmZmc7PTMos7aoCNit7auHvHRpnFovpmrNf1RsNEVFc5gVfDalTk1lLt7uV4rXwPngwAAOA5hgEAADzHMAAAgOcYBgAA8BzDAAAAnmMYAADAcx1XCysVXYVy7UIKma7sBYGeRRJdPfpFw45KXjEvs+Wqruv19A/o9zOzkGP7YLulz0Aiq+tlQUh/f8fbWTiktxb2JhIyqxZ1zTHh6A82Av39lh310MD0a7Zb+n6KxnQFshXVGwRbbf2aZmaRpN4GGEnoymJGfxxrOqqV9Za+99OO+2JpcVG/IQCsAp4MAADgOYYBAAA8xzAAAIDnGAYAAPAcwwAAAJ5jGAAAwHMdVwuLlcqKXsS1SS4I9JFNR50tML1Frh3V1bpkTNfH2m335qla3fGe5qod6hpg0HRse6zr48xR2XPVNUMxvUWwVHNtbdSfMxLR3z0c1p+l6dhaWGs4rkW9IaN42F0tTGUzMiuWde00FNZ1xmZb38ORqM7K+nayZLJHhwCwCngyAACA5xgGAADwHMMAAACeYxgAAMBzDAMAAHiOYQAAAM91XC2sOapndUd9MOxoyLUdlTVHK81cpbuQo5IYdtTg2o66opn7RNUr+thmWNfkQo6thWa6JueqD7oEga7lBY42n/P96o5tlm19XlzXIhLRZzsc0jW/at1VjzQrOeqaIUdFsOmohzZNn9Oao+kYcdRKaxe4FwHglcaTAQAAPMcwAACA5xgGAADwHMMAAACeYxgAAMBzDAMAAHguaLfbuuMEAABe83gyAACA5xgGAADwHMMAAACeYxgAAMBzDAMAAHiOYQAAAM8xDAAA4DmGAQAAPMcwAACA5/4HkpJF6NFBebwAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "draw(xdata[0], ydata[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxJE--lwterF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-5k-FbecrQX1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Assuming xdata and ydata are numpy arrays\n",
        "xdata_tensor = torch.tensor(xdata, dtype=torch.float32)\n",
        "ydata_tensor = torch.tensor(ydata, dtype=torch.float32)\n",
        "\n",
        "# Create a TensorDataset\n",
        "train_dataset = TensorDataset(xdata_tensor, ydata_tensor)\n",
        "\n",
        "# Define batch size and shuffle the data\n",
        "batch_size = 10\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaqQBZhtYEtn"
      },
      "source": [
        "The intersection over union (IOU) is a metric for measuring the performance of image segmentation. The perfect segmentation receives IOU of one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qYv6okdsy0Th"
      },
      "outputs": [],
      "source": [
        "# Do not change this cell\n",
        "def iou(ytrue, yprediction):\n",
        "    yp = yprediction\n",
        "    yt = ytrue\n",
        "    yp = yp > 0.5 + 0\n",
        "    intersect = np.sum(np.minimum(yp, yt),1)\n",
        "    union = np.sum(np.maximum(yp, yt),1)\n",
        "    return np.average(intersect / (union+0.0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xg72JBIOzG4B"
      },
      "outputs": [],
      "source": [
        "assert iou(ydata, ydata) == 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GupMJR57YnWt"
      },
      "source": [
        "We can use feedforwad CNN model for image segmentation. Here the input is the image and the output is the segmentation mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "656Hc95PvLqh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"Convolutional NNs baseline in PyTorch.\"\"\"\n",
        "\n",
        "    def __init__(self, image_size, num_classes=1, depth=4, base_channels=32, batch=4):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        self.depth = depth\n",
        "\n",
        "        # Encoder: each step halves the resolution\n",
        "        self.encoder_blocks = nn.ModuleList([self.conv_block(1, base_channels)])\n",
        "        for i in range(1, depth):\n",
        "            self.encoder_blocks.append(self.conv_block(base_channels * 2**(i-1), base_channels * 2**i))\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = self.conv_block(base_channels * 2**(depth-1), base_channels * 2**depth)\n",
        "\n",
        "        # Decoder: each step doubles the resolution\n",
        "        self.decoder_blocks = nn.ModuleList()\n",
        "        for i in range(depth, 0, -1):\n",
        "            self.decoder_blocks.append(self.upconv_block(base_channels * 2**i, base_channels * 2**(i-1)))\n",
        "\n",
        "        # Final convolution layer\n",
        "        self.final_conv = nn.Conv2d(base_channels, num_classes, kernel_size=1)\n",
        "        \n",
        "        # Optimizer\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=1e-5) \n",
        "\n",
        "        self.xbatch = batch\n",
        "        self.ybatch = batch\n",
        "\n",
        "    # Convolution block (two conv layers + ReLU)\n",
        "    def conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    # Upsample + Conv block\n",
        "    def upconv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
        "            self.conv_block(out_channels, out_channels)\n",
        "        )\n",
        "\n",
        "\n",
        "    #If the predict is true we are returning the sigmoid of the logits as the prediction value for each label\n",
        "    #If the predict is false we are returning the logits directly.\n",
        "    def forward(self, x, predict=False):\n",
        "        # Encoder path\n",
        "        for i in range(self.depth):\n",
        "            x = self.encoder_blocks[i](x)\n",
        "            x = F.max_pool2d(x, 2)\n",
        "            print(x.shape)\n",
        "\n",
        "        # Bottleneck\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        # Decoder path (no skip connections)\n",
        "        for i in range(self.depth):\n",
        "            x = F.interpolate(x, scale_factor=2)\n",
        "            x = self.decoder_blocks[i](x)\n",
        "            print(x.shape)\n",
        "\n",
        "        # Final layer\n",
        "        logits = self.final_conv(x)\n",
        "        if predict:\n",
        "            return torch.sigmoid(logits)\n",
        "        return logits\n",
        "\n",
        "    #Complete Me with the loss function\n",
        "    def get_loss(self, x, yt):\n",
        "        # the task is segmentation \n",
        "        # the loss function should be cross-entropy loss\n",
        "        logits = self.forward(x)\n",
        "        print(x.shape)\n",
        "        print(logits.shape)\n",
        "        print(yt.shape)\n",
        "        loss = nn.BCEWithLogitsLoss()(logits, yt)\n",
        "        return loss\n",
        "    \n",
        "    #Complete Me with the training step\n",
        "    def train_step(self):\n",
        "        \"\"\"Perform a single training step.\"\"\"\n",
        "        self.train()\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = self.get_loss(self.xbatch, self.ybatch)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "    def predict(self, x):\n",
        "        self.eval()  # Set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            y = self.forward(x, predict=True)\n",
        "        return y.cpu().numpy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SRclkbJiw42K"
      },
      "outputs": [],
      "source": [
        "model = CNN(image_size)\n",
        "train_iou = []\n",
        "val_iou = []\n",
        "test_iou = []\n",
        "epoch = 1;\n",
        "best_val_iou = -1;\n",
        "best_test_iou = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "YMLAf_wB1s2s"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\24084\\AppData\\Local\\Temp\\ipykernel_39812\\3521907493.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  xdata = torch.tensor(xdata, dtype=torch.float32)\n",
            "C:\\Users\\24084\\AppData\\Local\\Temp\\ipykernel_39812\\3521907493.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  xval = torch.tensor(xval, dtype=torch.float32)\n",
            "C:\\Users\\24084\\AppData\\Local\\Temp\\ipykernel_39812\\3521907493.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  xtest = torch.tensor(xtest, dtype=torch.float32)\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "CNN.train_step() takes 1 positional argument but 3 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[40], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m   xbatch \u001b[38;5;241m=\u001b[39m xbatch\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, image_size, image_size, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     20\u001b[0m   \u001b[38;5;66;03m# Run the training step and accumulate loss\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m   loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mybatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# print(xdata.shape)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m ydata_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(xdata\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, image_size, image_size, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m) );\n",
            "\u001b[1;31mTypeError\u001b[0m: CNN.train_step() takes 1 positional argument but 3 were given"
          ]
        }
      ],
      "source": [
        "#Adopt similar training loop for other problems\n",
        "\n",
        "max_epoch = 5000\n",
        "xdata = torch.tensor(xdata, dtype=torch.float32)\n",
        "xval = torch.tensor(xval, dtype=torch.float32)\n",
        "xtest = torch.tensor(xtest, dtype=torch.float32)\n",
        "\n",
        "while epoch < max_epoch:\n",
        "  loss = 0.0\n",
        "  for batch in train_loader:\n",
        "    xbatch, ybatch = batch  # Unpack the batch into inputs and targets\n",
        "\n",
        "    # Ensure the data is of type float32\n",
        "    xbatch = xbatch.float()\n",
        "    ybatch = ybatch.float()\n",
        "\n",
        "    # Reshape xbatch if needed (assuming xbatch is in shape (batch_size, 3, image_size, image_size))\n",
        "    xbatch = xbatch.view(-1, image_size, image_size, 3).permute(0,3,1,2)\n",
        "\n",
        "    # Run the training step and accumulate loss\n",
        "    loss += model.train_step(xbatch, ybatch)\n",
        "  # print(xdata.shape)\n",
        "\n",
        "  ydata_pred = model.predict(xdata.view(-1, image_size, image_size, 3).permute(0,3,1,2) );\n",
        "  yval_pred = model.predict(xval.view(-1, image_size, image_size, 3).permute(0,3,1,2) );\n",
        "  ytest_pred = model.predict(xtest.view(-1, image_size, image_size, 3).permute(0,3,1,2) );\n",
        "\n",
        "  train_iou.append(iou(ydata,ydata_pred))\n",
        "  # print(xval.shape)\n",
        "  val_iou.append(iou(yval,yval_pred))\n",
        "  test_iou.append(iou(ytest,ytest_pred))\n",
        "\n",
        "  if val_iou[-1] > best_val_iou:\n",
        "    best_test_iou = test_iou[-1]\n",
        "    best_val_iou = val_iou[-1]\n",
        "  display.clear_output(wait=False)\n",
        "\n",
        "  print(\"Epoch {}, Loss: {:0.3}, IOU - Train: {:0.3} Test: {:0.3}\".format( epoch, loss, train_iou[-1], best_test_iou))\n",
        "\n",
        "  fig, ax = plt.subplots(1,1)\n",
        "  pd.Series(train_iou).plot(ax=ax)\n",
        "  pd.Series(val_iou).plot(ax=ax)\n",
        "  pd.Series(test_iou).plot(ax=ax)\n",
        "  fig.canvas.draw()\n",
        "\n",
        "  draw(xdata[0], ydata_pred[0])\n",
        "\n",
        "  epoch += 1\n",
        "  # print(ybatch.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zwvz3uTqxuch"
      },
      "outputs": [],
      "source": [
        "ypred_test = model.predict(xtest.view(-1, image_size, image_size, 3).permute(0,3,1,2));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrsVhY_t6z10"
      },
      "outputs": [],
      "source": [
        "#Draw couple of examples:\n",
        "draw(xtest[4]/255.0, ypred_test[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1BeXFyeVjaz"
      },
      "outputs": [],
      "source": [
        "draw(xtest[10]/255.0, ypred_test[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jwQpT4fVp-l"
      },
      "outputs": [],
      "source": [
        "draw(xtest[20]/255.0, ypred_test[20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkAO0REWW3yw"
      },
      "source": [
        "### Gradient Descent-Based Inference for Minimizing the Energy of CRF\n",
        "\n",
        "Conditional Random Fields (CRFs) are graphical models used for structured prediction, where the objective is to model the relationships between input features and output labels, as well as dependencies among the output labels themselves. The goal of inference in CRFs is to find the optimal label configuration that minimizes the total energy of the CRF.\n",
        "\n",
        "The total energy $ E(\\mathbf{y}) $ of a CRF can be defined as the sum of univariate and pairwise potentials:\n",
        "\n",
        "\n",
        "$$E(\\mathbf{y}) = \\sum_{i} \\phi(y_i) + \\sum_{(i, j) \\in \\mathcal{E}} \\psi(y_i, y_j, d_{ij})\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $\\phi(y_i)$ is the univariate potential associated with label $y_i$.\n",
        "- $\\psi(y_i, y_j, d_{ij})$ is the pairwise potential between labels $y_i$ and $y_j$, which can be weighted by the distance $d_{ij}$ between the corresponding pixels or nodes.\n",
        "- $\\mathcal{E}$ denotes the set of edges in the graph that represent pairwise relationships.\n",
        "\n",
        "### Gradient Descent-Based Inference\n",
        "\n",
        "The objective of gradient descent-based inference is to minimize the energy $ E(\\mathbf{y}) $ with respect to the labels $\\mathbf{y}$. Since exact inference in CRFs is often intractable due to the complexity of the graphical structure, gradient descent provides an iterative, approximate approach to finding the optimal labels.\n",
        "\n",
        "#### Steps of Gradient Descent-Based Inference\n",
        "\n",
        "1. **Initialization**: Start with an initial label configuration, often using random values or a prior estimate. Ensure the labels are continuous (e.g., soft labels) to support gradient-based optimization.\n",
        "\n",
        "2. **Forward Pass**: Compute the univariate potentials $\\phi(y_i)$ using the CNN features and calculate the pairwise potentials $\\psi(y_i, y_j, d_{ij})$ using the Gaussian kernel weighted by pixel distances.\n",
        "\n",
        "3. **Compute Energy**: Calculate the total energy $E(\\mathbf{y})$ by summing the univariate and pairwise components.\n",
        "\n",
        "4. **Backpropagation**: Perform backpropagation to compute the gradients of the energy with respect to the labels:\n",
        "\n",
        "   $$\n",
        "   \\frac{\\partial E(\\mathbf{y})}{\\partial \\mathbf{y}}\n",
        "   $$\n",
        "\n",
        "5. **Gradient Update**: Update the labels using the gradients computed:\n",
        "\n",
        "   $$\n",
        "   \\mathbf{y} \\leftarrow \\mathbf{y} - \\eta \\frac{\\partial E(\\mathbf{y})}{\\partial \\mathbf{y}}\n",
        "   $$\n",
        "\n",
        "   where $\\eta$ is the learning rate.\n",
        "\n",
        "6. **Gradient Clipping**: Optionally, clip the gradients to prevent exploding gradients, which can destabilize the optimization:\n",
        "\n",
        "   $$\n",
        "   \\text{clip_gradients}(\\mathbf{y})\n",
        "   $$\n",
        "\n",
        "7. **Iterate**: Repeat the forward pass, energy computation, and gradient update steps for a predefined number of iterations or until convergence.\n",
        "\n",
        "### Final Label Assignment\n",
        "\n",
        "After iterating, the resulting label configuration $\\mathbf{y}$ should be close to the optimal solution that minimizes the CRF energy, taking into account both the unary potentials (data-driven) and the pairwise potentials (enforcing spatial coherence).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbjjaBUYPSAQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class CRF(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(CRF, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.sigma = 1.0\n",
        "        # Univariate potential: Linear layer for each label using CNN features\n",
        "        self.unary_weights = torch.ones(num_labels)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Compute unary potentials using CNN features\n",
        "        pass\n",
        "\n",
        "\n",
        "    #Calculate the energy of the CRF\n",
        "    def energy(self, labels, unary_potentials):\n",
        "        pass\n",
        "\n",
        "    #Gradient descent-based inference using CRF\n",
        "    def gradient_descent_inference(self, x, yt, max_iters=1000, lr=0.01):\n",
        "\n",
        "        inf_energy = []\n",
        "        inf_iou = []\n",
        "        # Initialize label assignments randomly\n",
        "\n",
        "        labels = torch.rand_like(cnn_features, requires_grad=True)\n",
        "\n",
        "        # Optimizer for label updates\n",
        "        optimizer = optim.SGD([labels], lr=lr)\n",
        "\n",
        "\n",
        "        for iter in range(max_iters):\n",
        "            #Complete Me with inference steps\n",
        "            energy =  ...\n",
        "\n",
        "            inf_energy.append(energy.detach().numpy().item())\n",
        "            inf_iou.append(iou(yt, labels.detach().numpy()))\n",
        "            if iter % 10 == 0:\n",
        "                display.clear_output(wait=False)\n",
        "                fig, (ax1, ax2) = plt.subplots(1,2)\n",
        "                pd.Series(inf_iou).plot(ax=ax1)\n",
        "                pd.Series(inf_energy).plot(ax=ax2)\n",
        "                fig.canvas.draw()\n",
        "                draw(x, labels.detach().numpy())\n",
        "        return labels\n",
        "\n",
        "num_labels = 32*32\n",
        "image_size = 32\n",
        "\n",
        "# Initialize CNN and CRF models\n",
        "crf = CRF(num_labels)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cocaWkKdFbO"
      },
      "outputs": [],
      "source": [
        "#Run this cell\n",
        "crf.gradient_descent_inference(xtest[0:1], ytest[0:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhZSoK15c7e2"
      },
      "outputs": [],
      "source": [
        "#Run this cell\n",
        "crf.gradient_descent_inference(xtest[4:5], ytest[4:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlRuKZqMc9sD"
      },
      "outputs": [],
      "source": [
        "#Run this cell\n",
        "crf.gradient_descent_inference(xtest[10:11], ytest[10:11])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVEwaQ4g92t3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
